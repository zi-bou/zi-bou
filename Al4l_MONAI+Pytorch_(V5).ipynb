{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLC+hL+TIrDMuFWO32cS72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zi-bou/zi-bou/blob/main/Al4l_MONAI%2BPytorch_(V5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Cardiac MRI Model Evolution Summary\n",
        "\n",
        "| Version | Model                      | Augmentation                         | Loss        | Notes                                                    | Train Acc | Val Acc |\n",
        "|---------|----------------------------|--------------------------------------|-------------|----------------------------------------------------------|-----------|---------|\n",
        "| V1      | ResNet18                   | None                                 | CrossEntropy| Baseline model                                            | 38%       | 30%     |\n",
        "| V2      | ResNet18                   | Basic 3D transforms                  | CrossEntropy| Added transforms to improve robustness                   | 43%       | 20%     |\n",
        "| V3      | ResNet18 + Dropout         | Basic transforms                     | CrossEntropy| Dropout and oversampling added                           | 37%       | 30%     |\n",
        "| V4      | ResNet18 + Dropout         | Class-specific (same for all)        | Focal Loss  | Introduced Focal Loss to handle class imbalance          | 43%       | 30%     |\n",
        "| V5      | DenseNet121 + Dropout      | Class-specific (same for all)        | Focal Loss  | Switched to DenseNet121, achieved better generalization  | 37.5%     | 35%     |\n"
      ],
      "metadata": {
        "id": "DUD5qG-poaTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 0: Uninstall conflicting versions completely\n",
        "!pip uninstall -y numpy numba tensorflow thinc\n",
        "\n",
        "#Reinstall safe NumPy + MONAI + friends\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai nibabel matplotlib scikit-learn torch torchvision torchaudio -q"
      ],
      "metadata": {
        "id": "e8Qd-hEdnCIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8765d1d-c602-4b90-b29d-5f1621e3a092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Found existing installation: thinc 8.3.6\n",
            "Uninstalling thinc-8.3.6:\n",
            "  Successfully uninstalled thinc-8.3.6\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.47.1 requires numba>=0.54, which is not installed.\n",
            "umap-learn 0.5.7 requires numba>=0.51.2, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\n",
            "pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n",
            "spacy 3.8.5 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "monai 1.4.0 requires numpy<2.0,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "56801d9197de4b638831c119cb085c04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.47.1 requires numba>=0.54, which is not installed.\n",
            "umap-learn 0.5.7 requires numba>=0.51.2, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\n",
            "pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n",
            "spacy 3.8.5 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai nibabel matplotlib scikit-learn -q"
      ],
      "metadata": {
        "id": "MtjnrPytq7q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Mount Google Drive\n",
        "# Mount Google Drive to access dataset stored in the user's drive.\n",
        "from google.colab import drive\n",
        "# This command will prompt a link and code to authorize access\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qtiG3tyrFNX",
        "outputId": "f143a4c2-1d07-477f-c141-6c5bb7df5707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 2: Import required libraries\n",
        "# numpy: numerical operations\n",
        "# nibabel: reading .nii.gz medical images\n",
        "# torch: PyTorch core library\n",
        "# sklearn: metrics and preprocessing\n",
        "# monai: medical deep learning models and transforms\n",
        "# matplotlib: plotting learning curves and confusion matrices\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.networks.nets import resnet18, densenet121\n",
        "from monai.transforms import Compose, RandFlip, RandRotate, RandGaussianNoise, RandZoom\n"
      ],
      "metadata": {
        "id": "pQQozWhSoG2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 3: Estimate volume shape using 90th percentile\n",
        "# Load a sample from each patient directory to extract its dimensions\n",
        "# We'll use the 90th percentile of depth (D) to avoid memory overflow from very deep volumes\n",
        "base_dir = '/content/drive/MyDrive/KAGGLE/Al4l/data/drive-download-20250107T191042Z-001/train'\n",
        "depths, heights, widths = [], [], []\n",
        "\n",
        "# Loop over all patient folders\n",
        "for pid in os.listdir(base_dir):\n",
        "    pdir = os.path.join(base_dir, pid)\n",
        "    if not os.path.isdir(pdir):\n",
        "        continue\n",
        "    files = os.listdir(pdir)\n",
        "    # We assume 'frame01' is always present and useful to extract volume shape\n",
        "    for f in files:\n",
        "        if 'frame01' in f and 'gt' not in f and f.endswith('.nii'):\n",
        "            vol = nib.load(os.path.join(pdir, f)).get_fdata()\n",
        "            h, w, d = vol.shape\n",
        "            heights.append(h)\n",
        "            widths.append(w)\n",
        "            depths.append(d)\n",
        "\n",
        "# Choose the final target shape used for resampling all volumes\n",
        "# These dimensions will be used throughout model training\n",
        "# 224x224 chosen for compatibility with pretrained CNNs and memory efficiency\n",
        "# Depth is set to the 90th percentile of observed depths\n",
        "target_height = 224\n",
        "target_width = 224\n",
        "target_depth = max(int(np.percentile(depths, 90)), 32) #If a volume’s depth (or height or width) is less than the target, the code pads it with zeros to reach the fixed size.\n",
        "print(f\"📏 Target shape (H, W, D): {target_height}, {target_width}, {target_depth}\")\n",
        "\n",
        "# ✅ Step 4: Define custom PyTorch Dataset for cardiac MRI\n",
        "# This class loads systolic/diastolic volumes for each patient, preprocesses them, and returns their label\n",
        "\n",
        "class CardiacDataset(Dataset): #This defines a custom dataset class that inherits from torch.utils.data.Dataset. It's how PyTorch knows how to load and access your data.\n",
        "    def __init__(self, data_dir, target_shape, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.target_height, self.target_width, self.target_depth = target_shape\n",
        "        self.patient_ids = [pid for pid in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, pid))]\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load ground-truth label for each patient\n",
        "        for pid in self.patient_ids:\n",
        "            label_path = os.path.join(data_dir, pid, 'gt.txt')\n",
        "            with open(label_path, 'r') as f:\n",
        "                self.labels.append(f.read().strip())\n",
        "\n",
        "        # Encode string labels into integers\n",
        "        self.encoder = LabelEncoder()\n",
        "        self.encoded_labels = self.encoder.fit_transform(self.labels)\n",
        "\n",
        "    def __len__(self): # Returns the total number of patients (i.e., samples) in the dataset\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def pad_or_crop(self, volume):\n",
        "        # Pad or crop each dimension to match the target shape\n",
        "        h, w, d = volume.shape\n",
        "        pad_h = max(self.target_height - h, 0)\n",
        "        pad_w = max(self.target_width - w, 0)\n",
        "        pad_d = max(self.target_depth - d, 0)\n",
        "\n",
        "        pad = (\n",
        "            (pad_h//2, pad_h - pad_h//2),\n",
        "            (pad_w//2, pad_w - pad_w//2),\n",
        "            (pad_d//2, pad_d - pad_d//2)\n",
        "        )\n",
        "\n",
        "        # Apply padding and crop to fixed size\n",
        "        volume = np.pad(volume, pad, mode='constant')\n",
        "        volume = volume[:self.target_height, :self.target_width, :self.target_depth]\n",
        "        return volume\n",
        "\n",
        "    def __getitem__(self, idx): #  this is the heart of this custom PyTorch Dataset\n",
        "        pid = self.patient_ids[idx]\n",
        "        pdir = os.path.join(self.data_dir, pid)\n",
        "        files = os.listdir(pdir)\n",
        "\n",
        "        # Identify systolic and diastolic image file\n",
        "        systolic, diastolic = None, None\n",
        "        for f in files:\n",
        "            if 'frame01' in f and 'gt' not in f and f.endswith('.nii'):\n",
        "                systolic = f\n",
        "            elif 'frame' in f and 'gt' not in f and 'frame01' not in f and f.endswith('.nii'):\n",
        "                diastolic = f\n",
        "\n",
        "        # Load and preprocess both volumes\n",
        "        systolic_data = self.pad_or_crop(nib.load(os.path.join(pdir, systolic)).get_fdata())\n",
        "        diastolic_data = self.pad_or_crop(nib.load(os.path.join(pdir, diastolic)).get_fdata())\n",
        "\n",
        "        # Combine as 2-channel input\n",
        "        combined = np.stack((systolic_data, diastolic_data), axis=0)\n",
        "        combined = combined / np.max(combined) # Normalize volume intensities to [0, 1] to ensure consistent input scale\n",
        "\n",
        "\n",
        "        # Convert to torch tensor and reorder axes to (C, D, H, W)\n",
        "        # Convert NumPy array to a PyTorch tensor so it can be used with transforms and models.\n",
        "        # As a general rule, keep data as NumPy during loading and preprocessing,\n",
        "        # and convert to tensor only right before it's returned or passed into the model.\n",
        "        combined = torch.tensor(combined, dtype=torch.float32)\n",
        "        # Rearrange tensor axes:\n",
        "        # From [C, H, W, D] → to [C, D, H, W] to match the input format expected by MONAI/PyTorch 3D models\n",
        "        combined = combined.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply optional transforms\n",
        "        if self.transform:\n",
        "            combined = self.transform(combined)\n",
        "\n",
        "        return combined, self.encoded_labels[idx]\n",
        "\n",
        "# ✅ Step 5: Class-specific data augmentations (can be customized per class)\n",
        "# For now, all classes use the same set of random transforms\n",
        "base_transform = Compose([\n",
        "    RandFlip(spatial_axis=0, prob=0.5),  # Random horizontal flip\n",
        "    RandRotate(range_x=0.1, prob=0.5),   # Random rotation\n",
        "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),  # Random zoom in/out\n",
        "    RandGaussianNoise(prob=0.3, mean=0.0, std=0.05)  # Add noise\n",
        "])\n",
        "\n",
        "class CardiacDatasetWithClassAugment(CardiacDataset):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # Apply same transform for each of the 5 classes\n",
        "        self.class_transforms = {i: base_transform for i in range(5)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = super().__getitem__(idx)\n",
        "        transform = self.class_transforms.get(y, None)\n",
        "        if transform:\n",
        "            x = transform(x)\n",
        "        return x, y\n",
        "\n",
        "# ✅ Step 6: Dataset preparation, class balancing with sampling\n",
        "# Create dataset and compute class weights\n",
        "# Define target shape and create dataset\n",
        "# Use weighted sampling to compensate for class imbalance\n",
        "target_shape = (target_height, target_width, target_depth)\n",
        "dataset = CardiacDatasetWithClassAugment(base_dir, target_shape)\n",
        "\n",
        "y_all = [dataset.encoded_labels[i] for i in range(len(dataset))]\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_all), y=y_all)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_indices = train_ds.indices if hasattr(train_ds, 'indices') else list(range(len(train_ds)))\n",
        "train_labels = [dataset.encoded_labels[i] for i in train_indices]\n",
        "train_weights = [class_weights[label] for label in train_labels]\n",
        "sampler = WeightedRandomSampler(train_weights, num_samples=len(train_weights), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=2, sampler=sampler)\n",
        "val_loader = DataLoader(val_ds, batch_size=2)\n",
        "# 🔥 Free up any unused memory from earlier operations (like data loading)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ✅ Step 7: Define MONAI DenseNet121 model with dropout\n",
        "class DenseNet121WithDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base_model = densenet121(spatial_dims=3, in_channels=2, out_channels=5)\n",
        "        self.backbone = base_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(1024, 5)  # 🔧 Define custom classifier layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"[DEBUG] Input shape to DenseNet:\", x.shape) # Should be [B, C, D, H, W]\n",
        "        # 🧠 This line passes the input through all convolutional layers of the DenseNet encoder\n",
        "        x = self.backbone.features(x) # [B, C, H, W, D]\n",
        "        print(\"[DEBUG] Shape after features:\", x.shape) # Should still be 5D, just with fewer spatial dims and more channels\n",
        "        # 🌀 Applies Global Average Pooling across the spatial dimensions (D, H, W)\n",
        "        x = F.adaptive_avg_pool3d(x, (1, 1, 1)) # This reduces the shape from [B, C, D, H, W] → [B, C, 1, 1, 1]\n",
        "        print(\"[DEBUG] After GAP:\", x.shape)\n",
        "        x = torch.flatten(x, 1) # Flatten into [B, C]\n",
        "        print(\"[DEBUG] After flatten:\", x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)  # → [B, 5]\n",
        "        print(\"[DEBUG] After classifier:\", x.shape)\n",
        "        return x\n",
        "\n",
        "model = DenseNet121WithDropout().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ✅ Step 8: Focal loss implementation to handle class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n",
        "\n",
        "criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "# ✅ Step 9: Training loop with early stopping and model checkpointing\n",
        "train_acc_list, val_acc_list = [], []\n",
        "train_loss_list, val_loss_list = [], []\n",
        "best_val_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    model.train()\n",
        "    running_loss, correct = 0.0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        try:\n",
        "          outputs = model(inputs)\n",
        "        except Exception as e:\n",
        "          print(\"[TRAIN ERROR] input shape:\", inputs.shape)\n",
        "          raise e\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_ds)\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(running_loss / len(train_loader))\n",
        "\n",
        "    model.eval()\n",
        "    val_correct, val_loss = 0, 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = val_correct / len(val_ds)\n",
        "    val_acc_list.append(val_acc)\n",
        "    val_loss_list.append(val_loss / len(val_loader))\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "        torch.save(model.state_dict(), \"/content/best_model_densenet121_v5.pth\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        if early_stop_counter >= 5:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# ✅ Step 10: Visualizations - learning curves and confusion matrix\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc_list, label='Train Accuracy')\n",
        "plt.plot(val_acc_list, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss_list, label='Train Loss')\n",
        "plt.plot(val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "display.plot(cmap='Blues')\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(y_all, bins=np.arange(6)-0.5, rwidth=0.8)\n",
        "plt.title(\"Distribution of Classes in the Dataset\")\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Best model saved at: /content/best_model_densenet121_v5.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e-dihmUKPwlO",
        "outputId": "29e81f14-3df6-4811-d027-4959fbb5f933",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📏 Target shape (H, W, D): 224, 224, 32\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 1: Train Acc = 0.2375, Val Acc = 0.2500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 2: Train Acc = 0.3000, Val Acc = 0.4500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 3: Train Acc = 0.3500, Val Acc = 0.2500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 4: Train Acc = 0.3250, Val Acc = 0.1000\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 5: Train Acc = 0.3750, Val Acc = 0.1500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 6: Train Acc = 0.3000, Val Acc = 0.2500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 7: Train Acc = 0.4125, Val Acc = 0.4500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 8: Train Acc = 0.3375, Val Acc = 0.2500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 9: Train Acc = 0.3750, Val Acc = 0.2500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 10: Train Acc = 0.4000, Val Acc = 0.3000\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 11: Train Acc = 0.5125, Val Acc = 0.3500\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "[DEBUG] Input shape to DenseNet: torch.Size([2, 2, 32, 224, 224])\n",
            "[DEBUG] Shape after features: torch.Size([2, 1024, 1, 7, 7])\n",
            "[DEBUG] After GAP: torch.Size([2, 1024, 1, 1, 1])\n",
            "[DEBUG] After flatten: torch.Size([2, 1024])\n",
            "[DEBUG] After classifier: torch.Size([2, 5])\n",
            "Epoch 12: Train Acc = 0.3750, Val Acc = 0.3500\n",
            "⏹️ Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at: /content/best_model_densenet121_v5.pth\n"
          ]
        }
      ]
    }
  ]
}