{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rr51AiBwXaqe",
        "3oiRu0DhTA8r"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTFzcHtGNFrhAE/5B/scQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zi-bou/zi-bou/blob/main/Al4l.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI4Imaging-Hackathon-2024**\n",
        "Classification of Heart disease based on cine MRI scan\n",
        "\n"
      ],
      "metadata": {
        "id": "EuSRN3EgPkF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification label :**\n",
        "*   NOR - Normal subjects\n",
        "*   MINF - Myocardial infarction\n",
        "*   DCM - Dilated cardiomyopathy\n",
        "*   HCM - Hypertrophic cardiomyopathy\n",
        "*   RV - Abnormal right ventricle\n"
      ],
      "metadata": {
        "id": "5vg5cVw56MRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data structure**\n",
        "\n",
        "\n",
        "/data/\n",
        "- **drive-download-20250107T191042Z-001/**\n",
        "  - **train/**\n",
        "    - `p0096/`\n",
        "    - `p0097/`\n",
        "    - `p0088/`\n",
        "    - `p0100/`\n",
        "    - `p0098/`\n",
        "    - `p0083/`\n",
        "    - `p0090/`\n",
        "    - `p0092/`\n",
        "    - `p0094/`\n",
        "    - `p0099/`\n",
        "  - **test/**\n",
        "    - Similar subdirectories as in `train/`\n",
        "  - `test_sample_submission.csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "pBDLpymV7T5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NIfTI : Neuroimaging Informatics Technology Initiative\n",
        "gt : ground truth"
      ],
      "metadata": {
        "id": "w111uPrW_FpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROI (Region of interests)\n",
        "The segmentation mask, e.g., p0001_frame01_gt.nii.gz, utilizes non-zero integer (i.e., 1-3) to highlight different anatomical structures of the heart. The numbers 1, 2, and 3 represent the right ventricle, left ventricle, and myocardium, respectively."
      ],
      "metadata": {
        "id": "-SgcdkVF5CG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "5WstrdFZPj0e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload files from your local system\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir='/content/drive/My Drive/'\n",
        "data_dir='/content/drive/My Drive/KAGGLE/Al4l/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJvjldUiZGYk",
        "outputId": "c82886cd-6460-451c-d2d6-60db9f2baff2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Process Nested ZIP and GZ Files in All Directories**"
      ],
      "metadata": {
        "id": "xT06XcqU8JTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to Process Nested ZIP and GZ Files in All Directories\n",
        "\n",
        "import os\n",
        "import gzip\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Initial setup\n",
        "data_dir = data_dir\n",
        "\n",
        "def process_compressed_files(directory):\n",
        "    \"\"\"\n",
        "    Recursively checks for ZIP and GZ files in the given directory and its subdirectories.\n",
        "    Extracts and removes compressed files until none are left.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        # List all files and subdirectories\n",
        "        compressed_files = []\n",
        "        subdirectories = []\n",
        "\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if file.endswith('.gz') or file.endswith('.zip'):\n",
        "                    compressed_files.append(os.path.join(root, file))\n",
        "            for dir in dirs:\n",
        "                subdirectories.append(os.path.join(root, dir))\n",
        "\n",
        "        # Ensure we process all compressed files before breaking\n",
        "        if not compressed_files:\n",
        "            print(\"No more compressed files to process.\")\n",
        "            break\n",
        "\n",
        "        # Process each compressed file\n",
        "        for compressed_file in compressed_files:\n",
        "            if compressed_file.endswith('.gz'):\n",
        "                extraction_path = os.path.splitext(compressed_file)[0]  # Remove .gz extension for output file\n",
        "\n",
        "                # Extract the GZ file\n",
        "                with gzip.open(compressed_file, 'rb') as f_in:\n",
        "                    with open(extraction_path, 'wb') as f_out:\n",
        "                        shutil.copyfileobj(f_in, f_out)\n",
        "                        print(f\"Extracted {compressed_file} to {extraction_path}\")\n",
        "\n",
        "                # Delete the processed GZ file to avoid reprocessing\n",
        "                os.remove(compressed_file)\n",
        "                print(f\"Deleted {compressed_file}\")\n",
        "\n",
        "            elif compressed_file.endswith('.zip'):\n",
        "                extraction_dir = os.path.splitext(compressed_file)[0]  # Remove .zip extension for output folder\n",
        "\n",
        "                # Create the extraction directory if it doesn't exist\n",
        "                os.makedirs(extraction_dir, exist_ok=True)\n",
        "\n",
        "                # Extract the ZIP file\n",
        "                with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(extraction_dir)\n",
        "                    print(f\"Extracted {compressed_file} to {extraction_dir}\")\n",
        "\n",
        "                # Delete the processed ZIP file to avoid reprocessing\n",
        "                os.remove(compressed_file)\n",
        "                print(f\"Deleted {compressed_file}\")\n",
        "\n",
        "        # Recursively process subdirectories\n",
        "        for sub_dir in subdirectories:\n",
        "            print(f\"Checking subdirectory: {sub_dir}\")\n",
        "            process_compressed_files(sub_dir)  # Recursive call to ensure all compressed files are processed\n",
        "\n",
        "# Start the recursive processing\n",
        "process_compressed_files(data_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ml1QSkcht-cO",
        "outputId": "ba78c538-ee19-473c-979a-fbdffb692dd1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No more compressed files to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=os.path.join(data_dir,\"drive-download-20250107T191042Z-001\")\n",
        "train_dir =os.path.join(data_dir, 'train')\n",
        "test_dir=os.path.join(data_dir, 'test')\n",
        "patient_ids = [f\"p{i:04d}\" for i in range(1, 101)]  # Generate patient IDs from p0001 to p0100\n"
      ],
      "metadata": {
        "id": "5yynZC1SYIYr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing_V2**"
      ],
      "metadata": {
        "id": "W1F5hAbc8Sx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "##############################\n",
        "# 1) locate_patient_data\n",
        "##############################\n",
        "\n",
        "def locate_patient_data(patient_id):\n",
        "    \"\"\"\n",
        "    Finds the systolic frame, diastolic frame, systolic mask, and diastolic mask for a patient.\n",
        "    Returns (file_names, paths, frames) or (None, None, None) on error.\n",
        "\n",
        "    'frames' will be a list of nib.Nifti1Image objects:\n",
        "      [systolic_img, diastolic_img, systolic_mask_img, diastolic_mask_img]\n",
        "    \"\"\"\n",
        "    patient_dir = os.path.join(train_dir, patient_id)\n",
        "    if not os.path.exists(patient_dir):\n",
        "        print(f\"Patient directory not found: {patient_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    files = os.listdir(patient_dir)\n",
        "    systolic_frame_file = None\n",
        "    diastolic_frame_file = None\n",
        "    systolic_mask_file = None\n",
        "    diastolic_mask_file = None\n",
        "\n",
        "    for file in files:\n",
        "        if \"frame01\" in file and \"gt\" not in file and file.endswith(\".nii\"):\n",
        "            systolic_frame_file = file\n",
        "        elif \"frame01\" in file and \"gt\" in file and file.endswith(\".nii\"):\n",
        "            systolic_mask_file = file\n",
        "        elif \"frame\" in file and \"gt\" not in file and \"frame01\" not in file and file.endswith(\".nii\"):\n",
        "            diastolic_frame_file = file\n",
        "        elif \"frame\" in file and \"gt\" in file and \"frame01_gt\" not in file and file.endswith(\".nii\"):\n",
        "            diastolic_mask_file = file\n",
        "\n",
        "    file_names = [systolic_frame_file, diastolic_frame_file, systolic_mask_file, diastolic_mask_file]\n",
        "    if None in file_names:\n",
        "        print(f\"Missing files for patient {patient_id}. Check the directory.\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Construct paths\n",
        "    systolic_path = os.path.join(patient_dir, systolic_frame_file)\n",
        "    diastolic_path = os.path.join(patient_dir, diastolic_frame_file)\n",
        "    systolic_mask_path = os.path.join(patient_dir, systolic_mask_file)\n",
        "    diastolic_mask_path = os.path.join(patient_dir, diastolic_mask_file)\n",
        "    label_path = os.path.join(patient_dir, \"gt.txt\")  # optional label\n",
        "\n",
        "    paths = [systolic_path, diastolic_path, systolic_mask_path, diastolic_mask_path, label_path]\n",
        "\n",
        "    # Load nibabel images (not .get_fdata() yet)\n",
        "    try:\n",
        "        systolic_img = nib.load(systolic_path)\n",
        "        diastolic_img = nib.load(diastolic_path)\n",
        "        systolic_mask_img = nib.load(systolic_mask_path)\n",
        "        diastolic_mask_img = nib.load(diastolic_mask_path)\n",
        "        frames = [systolic_img, diastolic_img, systolic_mask_img, diastolic_mask_img]\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading files for patient {patient_id}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    return file_names, paths, frames\n",
        "\n",
        "##############################\n",
        "# 2) Gather all spacings\n",
        "##############################\n",
        "\n",
        "def check_all_patient_spacings(patient_ids):\n",
        "    \"\"\"\n",
        "    Loops over all patient_ids, calls locate_patient_data,\n",
        "    and collects voxel spacings for systolic/diastolic frames + masks.\n",
        "\n",
        "    Returns: list of (sx, sy, sz) for all volumes.\n",
        "    \"\"\"\n",
        "    spacings_list = []\n",
        "\n",
        "    for pid in patient_ids:\n",
        "        file_names, paths, frames = locate_patient_data(pid)\n",
        "        if file_names and paths and frames:\n",
        "            try:\n",
        "                systolic_img, diastolic_img, systolic_mask_img, diastolic_mask_img = frames\n",
        "                # get_zooms() gives spacing\n",
        "                systolic_spacing = systolic_img.header.get_zooms()[:3]\n",
        "                diastolic_spacing = diastolic_img.header.get_zooms()[:3]\n",
        "                systolic_mask_spacing = systolic_mask_img.header.get_zooms()[:3]\n",
        "                diastolic_mask_spacing = diastolic_mask_img.header.get_zooms()[:3]\n",
        "\n",
        "                # Collect them\n",
        "                spacings_list.append(systolic_spacing)\n",
        "                spacings_list.append(diastolic_spacing)\n",
        "                spacings_list.append(systolic_mask_spacing)\n",
        "                spacings_list.append(diastolic_mask_spacing)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading spacing for patient {pid}: {e}\")\n",
        "\n",
        "    return spacings_list\n",
        "\n",
        "##############################\n",
        "# 3) Decide on 90th percentile\n",
        "##############################\n",
        "\n",
        "def decide_target_spacing(spacings_list, percentile=90):\n",
        "    \"\"\"\n",
        "    Compute e.g. the 90th percentile across each dimension (sx, sy, sz).\n",
        "    \"\"\"\n",
        "    arr = np.array(spacings_list)  # shape (N, 3)\n",
        "    target_sx = np.percentile(arr[:,0], percentile)\n",
        "    target_sy = np.percentile(arr[:,1], percentile)\n",
        "    target_sz = np.percentile(arr[:,2], percentile)\n",
        "    return (target_sx, target_sy, target_sz)\n",
        "\n",
        "##############################\n",
        "# 4) Resample volume\n",
        "##############################\n",
        "\n",
        "def resample_volume(nifti_img, target_spacing, is_label=False):\n",
        "    \"\"\"\n",
        "    Resample a nibabel image to target_spacing using scipy zoom.\n",
        "    is_label=True => nearest-neighbor (order=0).\n",
        "    is_label=False => linear interpolation (order=1).\n",
        "    Returns a NumPy array of resampled data.\n",
        "    \"\"\"\n",
        "    data = nifti_img.get_fdata()\n",
        "    orig_spacing = nifti_img.header.get_zooms()[:3]\n",
        "    scale_factors = (\n",
        "        orig_spacing[0]/target_spacing[0],\n",
        "        orig_spacing[1]/target_spacing[1],\n",
        "        orig_spacing[2]/target_spacing[2],\n",
        "    )\n",
        "    order = 0 if is_label else 1\n",
        "    resampled_data = zoom(data, scale_factors, order=order)\n",
        "    return resampled_data\n",
        "\n",
        "##############################\n",
        "# 5) Crop or Pad Volume\n",
        "##############################\n",
        "\n",
        "def crop_or_pad_mri(volume, target_shape=(256,256,16)):\n",
        "    \"\"\"\n",
        "    Crop or pad a volume to match (target_shape).\n",
        "    volume.shape => (Dx, Dy, Dz) or (H, W, D), etc.\n",
        "    Adjust to your convention.\n",
        "    We'll assume volume.shape => (H, W, Z)\n",
        "    and target_shape => (256,256,16).\n",
        "    \"\"\"\n",
        "\n",
        "    # If your dimension ordering is different (D, H, W),\n",
        "    # be consistent or rename variables as needed.\n",
        "    adjusted_volume = volume\n",
        "    for i, (dim, target_dim) in enumerate(zip(adjusted_volume.shape, target_shape)):\n",
        "        diff = target_dim - dim\n",
        "        if diff > 0:\n",
        "            # pad\n",
        "            pad_before = diff // 2\n",
        "            pad_after = diff - pad_before\n",
        "            pad_widths = [(0,0)]*3\n",
        "            pad_widths[i] = (pad_before, pad_after)\n",
        "            adjusted_volume = np.pad(adjusted_volume, pad_widths,\n",
        "                                     mode='constant', constant_values=0)\n",
        "        elif diff < 0:\n",
        "            # crop\n",
        "            crop_start = abs(diff)//2\n",
        "            crop_end = crop_start + target_dim\n",
        "            slices = [slice(None)]*3\n",
        "            slices[i] = slice(crop_start, crop_end)\n",
        "            adjusted_volume = adjusted_volume[tuple(slices)]\n",
        "    return adjusted_volume\n",
        "\n",
        "##############################\n",
        "# 6) Full Preprocessing\n",
        "##############################\n",
        "\n",
        "def preprocess_and_resample_all(patient_ids, target_spacing=(1.0,1.0,1.0), final_shape=(256,256,16)):\n",
        "    \"\"\"\n",
        "    For each patient:\n",
        "      - locate data\n",
        "      - resample (systolic/diastolic + masks) to target_spacing\n",
        "      - crop or pad each to final_shape\n",
        "      - stack frames, do normalization, etc.\n",
        "    Returns a list/dict of results.\n",
        "    \"\"\"\n",
        "    all_volumes = []\n",
        "\n",
        "    for pid in patient_ids:\n",
        "        file_names, paths, frames = locate_patient_data(pid)\n",
        "        if file_names and paths and frames:\n",
        "            systolic_img, diastolic_img, systolic_mask_img, diastolic_mask_img = frames\n",
        "\n",
        "            # 1) Resample\n",
        "            systolic_resampled = resample_volume(systolic_img, target_spacing, is_label=False)\n",
        "            diastolic_resampled = resample_volume(diastolic_img, target_spacing, is_label=False)\n",
        "            systolic_mask_resampled = resample_volume(systolic_mask_img, target_spacing, is_label=True)\n",
        "            diastolic_mask_resampled = resample_volume(diastolic_mask_img, target_spacing, is_label=True)\n",
        "\n",
        "            # 2) Crop/Pad to final_shape=(256,256,16)\n",
        "            systolic_resampled = crop_or_pad_mri(systolic_resampled, final_shape)\n",
        "            diastolic_resampled = crop_or_pad_mri(diastolic_resampled, final_shape)\n",
        "            systolic_mask_resampled = crop_or_pad_mri(systolic_mask_resampled, final_shape)\n",
        "            diastolic_mask_resampled = crop_or_pad_mri(diastolic_mask_resampled, final_shape)\n",
        "\n",
        "            # 3) Stack frames => shape (H, W, D, 2)\n",
        "            # If your shape is (256,256,16), then after stacking => (256,256,16,2)\n",
        "            combined_frames = np.stack((systolic_resampled, diastolic_resampled), axis=-1)\n",
        "\n",
        "            # 4) Normalize intensities (avoid division by zero if empty)\n",
        "            max_val = combined_frames.max()\n",
        "            if max_val > 0:\n",
        "                combined_frames = combined_frames / max_val\n",
        "\n",
        "            # Save final results\n",
        "            all_volumes.append({\n",
        "                'patient_id': pid,\n",
        "                'frames': combined_frames,   # shape (256,256,16,2)\n",
        "                'systolic_mask': systolic_mask_resampled,   # shape (256,256,16)\n",
        "                'diastolic_mask': diastolic_mask_resampled, # shape (256,256,16)\n",
        "                # Optionally store more: label, original spacing, etc.\n",
        "            })\n",
        "\n",
        "    return all_volumes\n",
        "\n",
        "################################\n",
        "# 7) Putting It All Together\n",
        "################################\n",
        "\n",
        "# 2) Gather all spacings\n",
        "spacings_list = check_all_patient_spacings(patient_ids)\n",
        "\n",
        "# 3) Compute 90th percentile\n",
        "target_spacing_90th = decide_target_spacing(spacings_list, percentile=90)\n",
        "print(\"Chosen 90th-percentile spacing:\", target_spacing_90th)\n",
        "\n",
        "# 4) Preprocess: resample to that spacing, then crop/pad to (256,256,16)\n",
        "all_preprocessed = preprocess_and_resample_all(\n",
        "    patient_ids=patient_ids,\n",
        "    target_spacing=target_spacing_90th,\n",
        "    final_shape=(256,256,16)\n",
        ")\n",
        "\n",
        "print(f\"\\nPreprocessed {len(all_preprocessed)} patients.\")\n",
        "print(\"Sample keys in first entry:\", all_preprocessed[0].keys() if all_preprocessed else \"No data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0StggbZltCsj",
        "outputId": "0d6cf99e-823c-4ecd-f951-e66256f6b710"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen 90th-percentile spacing: (1.7382799744606023, 1.7382799744606023, 10.0)\n",
            "\n",
            "Preprocessed 100 patients.\n",
            "Sample keys in first entry: dict_keys(['patient_id', 'frames', 'systolic_mask', 'diastolic_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization**"
      ],
      "metadata": {
        "id": "rr51AiBwXaqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "i1O0cAXVXqI7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_mri_and_mask(patient_id):\n",
        "    \"\"\"\n",
        "    Visualize a single slice from an MRI patient image and its corresponding segmentation mask.\n",
        "\n",
        "    Args:\n",
        "        patient_id (str): Patient ID (e.g., 'p0001').\n",
        "    \"\"\"\n",
        "    # Locate patient data\n",
        "    file_names, paths, frames = locate_patient_data(patient_id)\n",
        "\n",
        "    if not frames:\n",
        "        print(f\"No data found for patient {patient_id}.\")\n",
        "        return\n",
        "\n",
        "    # Check dimensions\n",
        "    print(f\"Systolic MRI Shape: {frames[0].shape}\")\n",
        "    print(f\"Diastolic MRI Shape: {frames[1].shape}\")\n",
        "    print(f\"Systolic Mask Shape: {frames[2].shape}\")\n",
        "    print(f\"Diastolic Mask Shape: {frames[3].shape}\")\n",
        "\n",
        "    # Load and print patient classification\n",
        "    label_path = paths[4]  # Label file is the fifth element in paths\n",
        "    try:\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            label = label_file.readline().strip()\n",
        "            print(f\"Patient Classification: {label}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Label file not found for patient {patient_id}.\")\n",
        "        return\n",
        "\n",
        "    # Choose slice index dynamically\n",
        "    slice_index = frames[0].shape[2] // 2\n",
        "\n",
        "    # Extract the slice for visualization\n",
        "    mri_systolic_slice = frames[0][:, :, slice_index]\n",
        "    systolic_mask_slice = frames[2][:, :, slice_index]\n",
        "\n",
        "    mri_diastolic_slice = frames[1][:, :, slice_index]\n",
        "    diastolic_mask_slice = frames[3][:, :, slice_index]\n",
        "\n",
        "    # Plot the MRI image and the segmentation mask\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    # MRI systolic slice\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.imshow(mri_systolic_slice, cmap='gray')\n",
        "    plt.title(\"MRI Systolic Slice\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Systolic segmentation mask\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.imshow(mri_systolic_slice, cmap='gray')  # Display the MRI slice as the background\n",
        "    plt.imshow(systolic_mask_slice, alpha=0.5, cmap='jet')  # Overlay the mask with transparency\n",
        "    plt.title(\"MRI Systolic Slice with Segmentation Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # MRI diastolic slice\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.imshow(mri_diastolic_slice, cmap='gray')\n",
        "    plt.title(\"MRI Diastolic Slice\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Diastolic segmentation mask\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.imshow(mri_diastolic_slice, cmap='gray')  # Display the MRI slice as the background\n",
        "    plt.imshow(diastolic_mask_slice, alpha=0.5, cmap='jet')  # Overlay the mask with transparency\n",
        "    plt.title(\"MRI Diastolic Slice with Segmentation Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout(pad=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "random_patient_id = np.random.choice(patient_ids)\n",
        "print(f\"Randomly selected patient ID: {random_patient_id}\")\n",
        "\n",
        "visualize_mri_and_mask(random_patient_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "collapsed": true,
        "id": "zp8eSoCRXyQV",
        "outputId": "276ec156-f14f-4982-9058-831c05ab0000"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected patient ID: p0053\n",
            "Systolic MRI Shape: (216, 256, 10)\n",
            "Diastolic MRI Shape: (216, 256, 10)\n",
            "Systolic Mask Shape: (216, 256, 10)\n",
            "Diastolic Mask Shape: (216, 256, 10)\n",
            "Patient Classification: HCM\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot slice image objects; consider using `img.slicer[slice]` to generate a sliced image (see documentation for caveats) or slicing image array data with `img.dataobj[slice]` or `img.get_fdata()[slice]`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-92cba9253441>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Randomly selected patient ID: {random_patient_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mvisualize_mri_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_patient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-92cba9253441>\u001b[0m in \u001b[0;36mvisualize_mri_and_mask\u001b[0;34m(patient_id)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Extract the slice for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmri_systolic_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0msystolic_mask_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nibabel/spatialimages.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mown\u001b[0m \u001b[0mrisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \"\"\"\n\u001b[0;32m--> 638\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0;34m'Cannot slice image objects; consider using `img.slicer[slice]` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;34m'to generate a sliced image (see documentation for caveats) or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot slice image objects; consider using `img.slicer[slice]` to generate a sliced image (see documentation for caveats) or slicing image array data with `img.dataobj[slice]` or `img.get_fdata()[slice]`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's check image shapes\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "shapes = []\n",
        "for patient_id in patient_ids:\n",
        "    patient_dir = os.path.join(train_dir, patient_id)\n",
        "    files = os.listdir(patient_dir)\n",
        "    for file in files:\n",
        "        if file.endswith(\".nii\"):\n",
        "            file_path = os.path.join(patient_dir, file)\n",
        "            data = nib.load(file_path).get_fdata()\n",
        "            print(f\"File: {file}, Shape: {data.shape}\")\n",
        "            shapes.append(data.shape)\n",
        "\n",
        "# Compute the median shape for each dimension\n",
        "median_shape = tuple(np.median(np.array(shapes), axis=0).astype(int))\n",
        "print(f\"Median shape: {median_shape}\")\n",
        "\n",
        "# Compute the 90 percentile\n",
        "percentile_90 = tuple(np.percentile(np.array(shapes), 90, axis=0).astype(int))\n",
        "print(f\"90th percentile shape: {percentile_90}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QyhEAo7n7Wgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build the model**"
      ],
      "metadata": {
        "id": "j5ayqR6fcBCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple Conv3D model with :\n",
        "* adam optimizer\n",
        "* he initializer\n",
        "* same padding\n",
        "* 80/20 train/validation split"
      ],
      "metadata": {
        "id": "qRYmnU8qnLvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_3d_cnn(input_shape=(256,256,16,2), num_classes=5):\n",
        "    \"\"\"\n",
        "    Build a 3D CNN model with Keras\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv3D(32, (3,3,3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer='he_normal'),\n",
        "        layers.MaxPooling3D((2,2,2)),\n",
        "\n",
        "        layers.Conv3D(64, (3,3,3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "        layers.MaxPooling3D((2,2,2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.Dense(num_classes, activation='softmax', kernel_initializer='he_normal')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "#Go through the entire dataset\n",
        "patient_ids = [f\"p{i:04d}\" for i in range(1, 101)]  # e.g., 100 patients\n",
        "\n",
        "# Preprocess the data\n",
        "inputs, labels = preprocess_and_resample_all(patient_ids, target_spacing=(1.0,1.0,1.0), final_shape=(256,256,16))\n",
        "\n",
        "# Split into train/val (80/20 here, but adjust as you like)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(\n",
        "    inputs, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Build model\n",
        "model = build_3d_cnn(input_shape=(256,256,16,2), num_classes=5)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print summary\n",
        "model.summary()\n",
        "\n",
        "# TRAIN ON THE ENTIRE DATASET (80% train, 20% val)\n",
        "history = model.fit(\n",
        "    train_data, train_labels,\n",
        "    validation_data=(val_data, val_labels),\n",
        "    epochs=20,  # recommended values between 50 to 100\n",
        "    batch_size=4 # recommended values between 2 to 8\n",
        ")\n"
      ],
      "metadata": {
        "id": "rsayYMA3cOxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "#VISUALIZE INTERMEDIATE LAYERS\n",
        "##########################\n",
        "\n",
        "# Create an activation model that outputs the feature maps of all layers\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "# Pick a single sample from your dataset\n",
        "sample_volume = train_data[0:1]  # shape => (1, 256, 256, 16, 2)\n",
        "\n",
        "# Get the activations\n",
        "activations = activation_model.predict(sample_volume)\n",
        "\n",
        "# Grab layer names (for plot titles)\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Visualize each layer's activations\n",
        "for layer_idx, layer_activation in enumerate(activations):\n",
        "    # If shape is (1, D, H, W, C) or something else, remove batch dimension\n",
        "    if layer_activation.ndim == 5:\n",
        "        # shape => (1, newD, newH, newW, newC)\n",
        "        layer_activation = layer_activation[0]  # (newD, newH, newW, newC)\n",
        "\n",
        "        D, H, W, C = layer_activation.shape\n",
        "        # We'll show the middle slice in depth\n",
        "        mid_slice = D // 2\n",
        "\n",
        "        # We'll try to display up to 8 channels in a row\n",
        "        cols = 8\n",
        "        rows = C // cols + 1\n",
        "\n",
        "        fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
        "        fig.suptitle(f\"Layer {layer_idx+1}: {layer_names[layer_idx]}\", fontsize=16)\n",
        "\n",
        "        for c in range(C):\n",
        "            ax = plt.subplot(rows, cols, c + 1)\n",
        "            # Show the middle slice for channel c\n",
        "            channel_slice = layer_activation[mid_slice, :, :, c]\n",
        "            plt.imshow(channel_slice, cmap='viridis', aspect='auto')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    elif layer_activation.ndim == 2:\n",
        "        # It's probably a Dense layer output with shape (1, features)\n",
        "        # or after Flatten with shape (1, features).\n",
        "        # We can skip or just print shape info\n",
        "        print(f\"Layer {layer_idx+1}: {layer_names[layer_idx]} output shape => {layer_activation.shape}. Skipping visualization.\")\n",
        "    else:\n",
        "        print(f\"Layer {layer_idx+1}: {layer_names[layer_idx]} has shape {layer_activation.shape}. Skipping.\")"
      ],
      "metadata": {
        "id": "W7XiPhVfXc2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}